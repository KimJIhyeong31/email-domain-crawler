import customtkinter as ctk
from urllib.parse import urlparse, urljoin
import requests
from bs4 import BeautifulSoup
import re
import threading
import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

# ======================== ì „ì—­ ë³€ìˆ˜ ========================
visited = set()                # ë°©ë¬¸í•œ URL ì €ì¥
found_page = None              # íƒ€ê²Ÿ ë„ë©”ì¸ì„ ì°¾ì€ í˜ì´ì§€ URL
found_via_mailto = False       # mailto ë§í¬ì—ì„œ ë°œê²¬ ì—¬ë¶€
other_domains = dict()         # ë°œê²¬ëœ ì „ì²´ ë„ë©”ì¸: {ë„ë©”ì¸: URL}
mailto_links = []              # ë°œê²¬ëœ mailto ë§í¬: [(mailtoì£¼ì†Œ, ì¶œì²˜ URL)]

# ======================== GUI ì„¤ì • ========================
ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("blue")

app = ctk.CTk()
app.title("ì´ë©”ì¼ë„ë©”ì¸ ê²€ìƒ‰")
app.geometry("500x450+900+500")

# Start URL ë¼ë²¨ ë° ì…ë ¥
label1 = ctk.CTkLabel(app, text="  ê³µì‹ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œ ì…ë ¥", font=("ë§‘ì€ ê³ ë”•", 15), anchor="w", width=460)
label1.pack(pady=(12, 0))
entry_url = ctk.CTkEntry(app, placeholder_text="https://www.example.com", width=460, height=40, font=("ë§‘ì€ ê³ ë”•", 14))
entry_url.pack(pady=5)

# Target Domain ë¼ë²¨ ë° ì…ë ¥
label2 = ctk.CTkLabel(app, text="  ì´ë©”ì¼ë„ë©”ì¸ ì£¼ì†Œ ì…ë ¥", font=("ë§‘ì€ ê³ ë”•", 15), anchor="w", width=460)
label2.pack(pady=(12, 0))
entry_domain = ctk.CTkEntry(app, placeholder_text="@example.com", width=460, height=40, font=("ë§‘ì€ ê³ ë”•", 14))
entry_domain.pack(pady=5)

# ê²°ê³¼ ë©”ì‹œì§€
result_label = ctk.CTkLabel(app, text="", font=("ë§‘ì€ ê³ ë”•", 14), text_color="lightgray", width=460)
result_label.pack(pady=(15, 5))

# ê²€ìƒ‰ ë„ë©”ì¸ í…ìŠ¤íŠ¸ ë°•ìŠ¤
label_other = ctk.CTkLabel(app, text="ê²€ìƒ‰ëœ ëª¨ë“  ì´ë©”ì¼ë„ë©”ì¸, URL :", font=("ë§‘ì€ ê³ ë”•", 14), anchor="w", width=460)
label_other.pack(pady=(12, 0))
text_other = ctk.CTkTextbox(app, width=460, height=120, font=("ë§‘ì€ ê³ ë”•", 13))
text_other.pack(pady=5)

# ======================== ë„ë©”ì¸ ìë™ ì±„ìš°ê¸° ========================
def update_domain_default(event=None):
    url = entry_url.get().strip()
    if not url:
        return
    parsed = urlparse(url)
    domain = parsed.netloc.replace("www.", "")
    if domain:
        entry_domain.delete(0, 'end')
        entry_domain.insert(0, f"@{domain}")

entry_url.bind("<FocusOut>", update_domain_default)

# ======================== ë‚´ë¶€ë§í¬ íŒë³„ ========================
def is_internal_link(base_url, link):
    if not link:
        return False
    parsed_base = urlparse(base_url)
    parsed_link = urlparse(link)
    exclude_schemes = ('mailto', 'javascript', 'tel', 'data')
    if parsed_link.scheme in exclude_schemes:
        return False
    if link.strip().startswith('#') or parsed_link.path.endswith(('.pdf', '.zip', '.exe')):
        return False
    return parsed_base.netloc == parsed_link.netloc

# ======================== í¬ë¡¤ë§ í•¨ìˆ˜ ========================
def crawl(url, target_domain):
    global found_page, found_via_mailto
    if url in visited or found_page:
        return
    visited.add(url)

    def update_status():
        result_label.configure(text=f"ğŸ” ê²€ìƒ‰ ì¤‘: {url}", text_color="lightblue")
        app.update_idletasks()
    app.after(0, update_status)

    try:
        res = requests.get(
            url,
            headers={
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/114.0.0.0 Safari/537.36"
                )
            },
            timeout=10
        )
        res.raise_for_status()
        soup = BeautifulSoup(res.text, 'html.parser')

        text = soup.get_text()
        found_emails = set(re.findall(r'@[\w.-]+\.\w+\b', text))
        for em in found_emails:
            if em not in other_domains:
                other_domains[em] = url

        # í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼ ë„ë©”ì¸ ê²€ìƒ‰
        if target_domain.lower() in text.lower():
            found_page = url
            return

        # mailto ë§í¬ ìˆ˜ì§‘
        a_tags = soup.find_all('a', href=True)
        for a_tag in a_tags:
            href = a_tag['href'].strip().lower()
            if href.startswith("mailto:"):
                full_url = urljoin(url, href)
                if (full_url, url) not in mailto_links:
                    mailto_links.append((full_url, url))

        # ë§í¬ ë²„í‚·: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ë¶„ë¥˜
        buckets = {1: [], 2: [], 3: [], 4: [], 5: [], 7: []}
        for a_tag in a_tags:
            href = a_tag['href'].strip()
            text_a = a_tag.get_text(strip=True).lower()
            full_url = urljoin(url, href)
            href_lower = href.lower()
            if (href_lower.startswith(('mailto:', 'javascript:', 'tel:', 'data:', '#'))
                or a_tag.has_attr("download")):
                continue
            if 'privacy' in href_lower or 'privacy' in text_a or 'ê°œì¸ì •ë³´' in text_a:
                buckets[1].append(full_url)
            elif 'terms' in href_lower or 'terms' in text_a or 'ì´ìš©ì•½ê´€' in text_a:
                buckets[2].append(full_url)
            elif any(k in href_lower for k in ['support', 'help', 'service']) or 'ê³ ê°' in text_a:
                buckets[3].append(full_url)
            elif any(k in href_lower for k in ['notice', 'news', 'announcement']) or 'ê³µì§€' in text_a:
                buckets[4].append(full_url)
            elif any(k in href_lower for k in ['recruit', 'career', 'job']) or 'ì°¨ìš©' in text_a:
                buckets[5].append(full_url)
            else:
                buckets[7].append(full_url)

        # ë‚´ë¶€ ë§í¬ ì¬ê·€ í¬ë¡¤ë§
        for i in [1, 2, 3, 4, 5, 7]:
            for link in buckets[i]:
                if is_internal_link(url, link):
                    crawl(link, target_domain)
                    if found_page:
                        return

        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: mailto ê²€ì‚¬
        for mailto_url, source_url in mailto_links:
            email = mailto_url[len("mailto:"):].split('?')[0].strip()
            if target_domain.lower() in email.lower():
                found_page = source_url
                found_via_mailto = True
                return


    except Exception as e:
        err_msg = f"â— ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        app.after(0, lambda: result_label.configure(text=err_msg, text_color="orange"))

# ======================== Selenium ìº¡ì²˜ ========================
def selenium_highlight(target_url, target_domain):
    options = Options()
    options.add_argument("--start-maximized")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(target_url)
    time.sleep(2)

    # í˜ì´ì§€ ë‚´ ë„ë©”ì¸ í…ìŠ¤íŠ¸ë¥¼ í•˜ì´ë¼ì´íŒ…í•˜ëŠ” JavaScript
    highlight_script = f"""
    const walker = document.createTreeWalker(document.body, NodeFilter.SHOW_TEXT, null);
    let node;
    let found = false;

    while (node = walker.nextNode()) {{
        const text = node.nodeValue;
        const index = text.indexOf("{target_domain}");
        if (index !== -1) {{
            const span = document.createElement('span');
            span.style.backgroundColor = 'yellow';

            const before = document.createTextNode(text.slice(0, index));
            const highlight = document.createTextNode(text.slice(index, index + "{target_domain}".length));
            const after = document.createTextNode(text.slice(index + "{target_domain}".length));

            span.appendChild(highlight);

            const parent = node.parentNode;
            parent.insertBefore(before, node);
            parent.insertBefore(span, node);
            parent.insertBefore(after, node);
            parent.removeChild(node);

            span.scrollIntoView({{ behavior: "auto", block: "center" }});
            found = true;
            break;
        }}
    }}
    return found;
    """
    found = driver.execute_script(highlight_script)
    if found:
        time.sleep(2)
        save_name = f"{target_domain.replace('@', 'at_').replace('.', '_')}.png"
        driver.save_screenshot(save_name)
    driver.quit()
    return found

# ======================== ë„ë©”ì¸ ëª©ë¡ ì‹¤ì‹œê°„ ì¶œë ¥ ========================
def update_other_domains():
    text_other.configure(state="normal")
    text_other.delete("1.0", "end")
    for dom in sorted(other_domains.keys()):
        url = other_domains[dom]
        text_other.insert("end", f"{dom}  URL : {url}\n")
    text_other.configure(state="disabled")
    app.after(3000, update_other_domains)

# ======================== ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ========================
def on_click():
    global visited, found_page, found_via_mailto, other_domains, mailto_links
    visited, other_domains, mailto_links = set(), dict(), []
    found_page = None
    found_via_mailto = False

    start_url = entry_url.get().strip()
    target_domain = entry_domain.get().strip()

    if not start_url or not target_domain:
        result_label.configure(text="â— ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œì™€ ë„ë©”ì¸ì„ 'ëª¨ë‘' ì…ë ¥í•´ì£¼ì„¸ìš”.", text_color="orange")
        return

    def run():
        result_label.configure(text="ğŸ” ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.", text_color="lightblue")
        app.update_idletasks()
        crawl(start_url, target_domain)

        if found_page:
            if found_via_mailto:
                result_label.configure(text=f"âœ… mailto ë§í¬ì—ì„œ ë„ë©”ì¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n{found_page}", text_color="lightgreen")
            else:
                result_label.configure(text=f"âœ… ë„ë©”ì¸ í¬í•¨ í˜ì´ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n{found_page}", text_color="lightgreen")
                result_label.configure(text="ğŸ” ë„ë©”ì¸ ìº¡ì²˜ ì‚¬ì „ ì¤€ë¹„ ì¤‘", text_color="lightblue")
                app.update_idletasks()
                success = selenium_highlight(found_page, target_domain)
                if success:
                    result_label.configure(text="ğŸ“¸ ë„ë©”ì¸ ìº¡ì²˜ ì™„ë£Œ!", text_color="lightgreen")
                else:
                    result_label.configure(text="â— ë„ë©”ì¸ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (Selenium).", text_color="red")
        else:
            result_label.configure(text="âŒ ë„ë©”ì¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", text_color="red")

    threading.Thread(target=run, daemon=True).start()

# ======================== ë²„íŠ¼ UI ========================
btn_frame = ctk.CTkFrame(app, fg_color="transparent")
btn_frame.pack(pady=(7, 0))

# í™•ì¸ ë²„íŠ¼
btn_confirm = ctk.CTkButton(
    btn_frame,
    text="í™•ì¸",
    command=on_click,
    width=120,
    height=35,
    font=("ë§‘ì€ ê³ ë”•", 14),
    text_color="white",
    corner_radius=10
)
btn_confirm.grid(row=0, column=0, padx=10)

# ì¢…ë£Œ ë²„íŠ¼
btn_exit = ctk.CTkButton(
    btn_frame,
    text="ì¢…ë£Œ",
    command=app.destroy,
    width=120,
    height=35,
    font=("ë§‘ì€ ê³ ë”•", 14),
    text_color="black",
    fg_color="gray",
    corner_radius=10
)
btn_exit.grid(row=0, column=1, padx=10)
# ======================== ì‹¤ì‹œê°„ ì¶œë ¥ ì‹œì‘ ========================
update_other_domains()
app.mainloop()
